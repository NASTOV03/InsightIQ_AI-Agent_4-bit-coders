# 🧠 InsightIQ - AI-Powered Cognitive Companion&#x20;

InsightIQ is an advanced **Agentic AI Assistant** powered by IBM Watsonx and grounded with vectorized knowledge to deliver high-context, intelligent, and insightful answers. Designed as a foundational prototype for educational and knowledge-enhancing use cases, it leverages **LLaMA 3 Vision-Instruct (11B)** to create an always-available, vision-aware AI assistant. 🚀🤖

---

## 🧩 SMART CONTEXTUAL INTELLIGENCE FOR REAL-TIME USE

### 📌 Overview

InsightIQ is an experimental IBM Watsonx-powered AI assistant using the **meta-llama/llama-3-2-11b-vision-instruct** model. It is enhanced through **vector-based knowledge retrieval** using a PDF knowledge base, making it capable of **deep contextual understanding** across multi-turn conversations.

Whether you're a researcher, student, or developer—InsightIQ helps you query data-rich documents in natural language with grounded, AI-generated responses.

---

### 🚀 Features

🔍 **Vision + Language Intelligence**
Understands and processes visual inputs and text with LLaMA 3 Vision-Instruct.

🧠 **Agentic Reasoning Engine**
Driven by IBM Watsonx Agentic AI lab with pre-built tools, steps, and functions for intelligent conversations.

📚 **Vectorized Knowledge Base**
PDF files are uploaded, vectorized, and used to ground responses—ensuring factual accuracy from trusted documents.

🔁 **Memory-like Contextual Flow**
Supports multi-turn conversations using Watsonx agentic flows.

---

## 🧱 Project Architecture

| Layer            | Technology                               |
| ---------------- | ---------------------------------------- |
| AI Agent Chat    | Watsonx Agentic AI                       |
| LLM Model        | meta-llama/llama-3-2-11b-vision-instruct |
| Vector Knowledge | PDF (Indexed via Watsonx Lab)            |
| Platform         | IBM Cloud Watsonx.ai                     |
| Code / Logic     | IBM Jupyter Notebook                     |

---

## 📷 Project Snapshots

📌 **Project ID & Description**
<img width="1920" height="854" alt="Image" src="https://github.com/user-attachments/assets/375b5fad-93d4-42cd-a1fe-af589bc196a7" />

📌 **Setting up Vector Knowledge**
<img width="1746" height="808" alt="Image" src="https://github.com/user-attachments/assets/7a25b224-17fb-48d6-b3e6-fc50019d8f2f" />

📌 **Agent Instructions (Step Flow)**
<img width="1920" height="834" alt="Image" src="https://github.com/user-attachments/assets/a8c60621-1621-4245-a65c-122d28e87d0e" />

<img width="1800" height="845" alt="Image" src="https://github.com/user-attachments/assets/05f56b38-d6d1-4e92-8ccb-664bd03005f6" />

<img width="1755" height="802" alt="Image" src="https://github.com/user-attachments/assets/a03ef758-1978-427b-a043-b0aa7ad6e709" />

📌 **Model Selection & Tool Configuration**
<img width="888" height="811" alt="Image" src="https://github.com/user-attachments/assets/b197c415-e224-45a1-94a5-7c22be2ae629" />

📌 **Final Agent Deployment Preview**
<img width="1920" height="810" alt="Image" src="https://github.com/user-attachments/assets/3dca3a3c-d5bc-4b2e-8fc8-dcfe3b7a1907" />

<img width="1920" height="841" alt="Image" src="https://github.com/user-attachments/assets/3e6b7824-d075-4ab7-9372-6ab114d3b89d" />

<img width="778" height="693" alt="Image" src="https://github.com/user-attachments/assets/7e5f2ddf-8ce6-4114-8313-eaba172f2beb" />

<img width="596" height="735" alt="Image" src="https://github.com/user-attachments/assets/7a727262-9ac7-40c4-8e8f-6f5b0345ea8b" />

<img width="773" height="677" alt="Image" src="https://github.com/user-attachments/assets/871418bb-476d-4bfe-bb25-06327cc0bb75" />

<img width="589" height="753" alt="Image" src="https://github.com/user-attachments/assets/426a3b66-0385-47c0-8e70-874e8c7edae6" />

*Graph Visualization*

<img width="738" height="483" alt="Image" src="https://github.com/user-attachments/assets/f85ce9f4-1495-434c-a340-c9006a4c54e6" />

*Collab Preview*

<img width="1398" height="764" alt="Image" src="https://github.com/user-attachments/assets/07ef929f-d087-4789-9648-dbc0b6058fc1" />

📂 (See `Project ScreenShots/` folder for images)

---

## 🔧 Setup Instructions

### 🔴 Requirements

* IBM Cloud Account (Lite Plan is sufficient)
* Access to **Watsonx Agentic AI Lab**
* Uploaded knowledge PDF (for grounding)
* Optional: IBM Jupyter Notebook (for logic tweaking)

---

## 🧪 How to Use

1️⃣ Upload your knowledge base under **Knowledge → Documents**

2️⃣ Create a new AI Agent

3️⃣ Select the model `meta-llama/llama-3-2-11b-vision-instruct`

4️⃣ Add tools, steps, and instructions via drag-and-drop

5️⃣ Test your assistant in the **Try it** panel

6️⃣ Export / deploy for future usage (can be integrated later into web or app)

---

## 📦 Project Structure

```bash
📦 InsightIQ
├── Project ScreenShots/
├── InsightIQ Knowledge Base.pdf     # Vectorized knowledge document
├── InsightIQ.ipynb                  # IBM Notebook for logic setup
├── InsightIQ.txt
├── LICENSE
├── Problem Statement.pdf
├── README.md                        # This file
├── Project PPT.ppt

```
---

## **📝 Contributing**
Suggestions and forks are welcome! Feel free to contribute!

---

## **⚖️ License**
This project is licensed under the **MIT License** – free to use and modify.

---

## **🤝 Connect**
Made with 💙 by **4-bit coders**  

---

🔥 Powered by IBM Cloud, Built for Learners! 🔥
